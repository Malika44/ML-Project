{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ac0a88-6f5e-4e43-8433-9930f44f98c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from wordcloud) (11.1.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from wordcloud) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from matplotlib->wordcloud) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from matplotlib->wordcloud) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from matplotlib->wordcloud) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/py39_ml/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
      "Downloading wordcloud-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (513 kB)\n",
      "Installing collected packages: wordcloud\n",
      "\u001b[33m  WARNING: The script wordcloud_cli is installed in '/home/Hibatullah.saleh2000/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed wordcloud-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9423928e-b118-470f-bf8f-41e6e172d6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MOVIE REVIEW SENTIMENT ANALYSIS PROJECT\n",
      "Models: Logistic Regression + Decision Tree + Naive Bayes\n",
      "Threshold: >=60% = Fresh, <60% = Rotten\n",
      "============================================================\n",
      "\n",
      "Dataset Shape: (17711, 23)\n",
      "\n",
      "First 5 rows:\n",
      "                    rotten_tomatoes_link  \\\n",
      "0                              m/0814255   \n",
      "1                              m/0878835   \n",
      "2                                   m/10   \n",
      "3                 m/1000013-12_angry_men   \n",
      "4  m/1000079-20000_leagues_under_the_sea   \n",
      "\n",
      "                                         movie_title  \\\n",
      "0  Percy Jackson & the Olympians: The Lightning T...   \n",
      "1                                        Please Give   \n",
      "2                                                 10   \n",
      "3                    12 Angry Men (Twelve Angry Men)   \n",
      "4                       20,000 Leagues Under The Sea   \n",
      "\n",
      "                                          movie_info  \\\n",
      "0  Always trouble-prone, the life of teenager Per...   \n",
      "1  Kate (Catherine Keener) and her husband Alex (...   \n",
      "2  A successful, middle-aged Hollywood songwriter...   \n",
      "3  Following the closing arguments in a murder tr...   \n",
      "4  In 1866, Professor Pierre M. Aronnax (Paul Luk...   \n",
      "\n",
      "                                   critics_consensus content_rating  \\\n",
      "0  Though it may seem like just another Harry Pot...             PG   \n",
      "1  Nicole Holofcener's newest might seem slight i...              R   \n",
      "2  Blake Edwards' bawdy comedy may not score a pe...              R   \n",
      "3  Sidney Lumet's feature debut is a superbly wri...             NR   \n",
      "4  One of Disney's finest live-action adventures,...              G   \n",
      "\n",
      "                                              genres          directors  \\\n",
      "0  Action & Adventure, Comedy, Drama, Science Fic...     Chris Columbus   \n",
      "1                                             Comedy  Nicole Holofcener   \n",
      "2                                    Comedy, Romance      Blake Edwards   \n",
      "3                                    Classics, Drama       Sidney Lumet   \n",
      "4           Action & Adventure, Drama, Kids & Family  Richard Fleischer   \n",
      "\n",
      "                                      authors  \\\n",
      "0  Craig Titley, Chris Columbus, Rick Riordan   \n",
      "1                           Nicole Holofcener   \n",
      "2                               Blake Edwards   \n",
      "3                               Reginald Rose   \n",
      "4                                 Earl Felton   \n",
      "\n",
      "                                              actors original_release_date  \\\n",
      "0  Logan Lerman, Brandon T. Jackson, Alexandra Da...             2/12/2010   \n",
      "1  Catherine Keener, Amanda Peet, Oliver Platt, R...             4/30/2010   \n",
      "2  Dudley Moore, Bo Derek, Julie Andrews, Robert ...             10/5/1979   \n",
      "3  Martin Balsam, John Fiedler, Lee J. Cobb, E.G....             4/13/1957   \n",
      "4  James Mason, Kirk Douglas, Paul Lukas, Peter L...              1/1/1954   \n",
      "\n",
      "   ... tomatometer_status  tomatometer_rating tomatometer_count  \\\n",
      "0  ...             Rotten                49.0             149.0   \n",
      "1  ...    Certified-Fresh                87.0             142.0   \n",
      "2  ...              Fresh                67.0              24.0   \n",
      "3  ...    Certified-Fresh               100.0              54.0   \n",
      "4  ...              Fresh                89.0              27.0   \n",
      "\n",
      "  audience_status  audience_rating  audience_count  \\\n",
      "0         Spilled             53.0        254421.0   \n",
      "1         Upright             64.0         11574.0   \n",
      "2         Spilled             53.0         14684.0   \n",
      "3         Upright             97.0        105386.0   \n",
      "4         Upright             74.0         68918.0   \n",
      "\n",
      "  tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
      "0                            43                               73   \n",
      "1                            44                              123   \n",
      "2                             2                               16   \n",
      "3                             6                               54   \n",
      "4                             5                               24   \n",
      "\n",
      "   tomatometer_rotten_critics_count  \\\n",
      "0                                76   \n",
      "1                                19   \n",
      "2                                 8   \n",
      "3                                 0   \n",
      "4                                 3   \n",
      "\n",
      "                                      review_content  \n",
      "0  A fantasy adventure that fuses Greek mythology...  \n",
      "1  Uma Thurman as Medusa, the gorgon with a coiff...  \n",
      "2  With a top-notch cast and dazzling special eff...  \n",
      "3  Whether audiences will get behind The Lightnin...  \n",
      "4  What's really lacking in The Lightning Thief i...  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "==================================================\n",
      "STEP 2: DATA EXPLORATION & UNDERSTANDING\n",
      "==================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17711 entries, 0 to 17710\n",
      "Data columns (total 23 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   rotten_tomatoes_link              17711 non-null  object \n",
      " 1   movie_title                       17711 non-null  object \n",
      " 2   movie_info                        17390 non-null  object \n",
      " 3   critics_consensus                 9133 non-null   object \n",
      " 4   content_rating                    17711 non-null  object \n",
      " 5   genres                            17692 non-null  object \n",
      " 6   directors                         17517 non-null  object \n",
      " 7   authors                           16169 non-null  object \n",
      " 8   actors                            17359 non-null  object \n",
      " 9   original_release_date             16545 non-null  object \n",
      " 10  streaming_release_date            17327 non-null  object \n",
      " 11  runtime                           17397 non-null  float64\n",
      " 12  production_company                17212 non-null  object \n",
      " 13  tomatometer_status                17667 non-null  object \n",
      " 14  tomatometer_rating                17667 non-null  float64\n",
      " 15  tomatometer_count                 17667 non-null  float64\n",
      " 16  audience_status                   17263 non-null  object \n",
      " 17  audience_rating                   17415 non-null  float64\n",
      " 18  audience_count                    17414 non-null  float64\n",
      " 19  tomatometer_top_critics_count     17711 non-null  int64  \n",
      " 20  tomatometer_fresh_critics_count   17711 non-null  int64  \n",
      " 21  tomatometer_rotten_critics_count  17711 non-null  int64  \n",
      " 22  review_content                    16685 non-null  object \n",
      "dtypes: float64(5), int64(3), object(15)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "rotten_tomatoes_link                   0\n",
      "movie_title                            0\n",
      "movie_info                           321\n",
      "critics_consensus                   8578\n",
      "content_rating                         0\n",
      "genres                                19\n",
      "directors                            194\n",
      "authors                             1542\n",
      "actors                               352\n",
      "original_release_date               1166\n",
      "streaming_release_date               384\n",
      "runtime                              314\n",
      "production_company                   499\n",
      "tomatometer_status                    44\n",
      "tomatometer_rating                    44\n",
      "tomatometer_count                     44\n",
      "audience_status                      448\n",
      "audience_rating                      296\n",
      "audience_count                       297\n",
      "tomatometer_top_critics_count          0\n",
      "tomatometer_fresh_critics_count        0\n",
      "tomatometer_rotten_critics_count       0\n",
      "review_content                      1026\n",
      "dtype: int64\n",
      "\n",
      "Tomatometer Status Distribution:\n",
      "tomatometer_status\n",
      "Rotten             7565\n",
      "Fresh              6843\n",
      "Certified-Fresh    3259\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tomatometer Rating Statistics:\n",
      "count    17667.000000\n",
      "mean        60.884587\n",
      "std         28.444143\n",
      "min          0.000000\n",
      "25%         38.000000\n",
      "50%         67.000000\n",
      "75%         86.000000\n",
      "max        100.000000\n",
      "Name: tomatometer_rating, dtype: float64\n",
      "\n",
      "==================================================\n",
      "STEP 3: DATA PREPARATION & FEATURE ENGINEERING\n",
      "==================================================\n",
      "Text cleaning completed!\n",
      "Sample cleaned text: a fantasy adventure that fuses greek mythology to contemporary american places and values anyone aro...\n",
      "\n",
      "Target variable created with threshold: 60%\n",
      "Target distribution:\n",
      "target\n",
      "1    10102\n",
      "0     7609\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "STEP 4: ML MODEL SELECTION & EVALUATION\n",
      "==================================================\n",
      "Training set size (combined features): (12397, 1006)\n",
      "Test set size (combined features): (5314, 1006)\n",
      "Training set size (text features only): (12397, 1000)\n",
      "Test set size (text features only): (5314, 1000)\n",
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.5294\n",
      "AUC-ROC: 0.4909\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Rotten       0.41      0.22      0.29      2283\n",
      "       Fresh       0.56      0.76      0.65      3031\n",
      "\n",
      "    accuracy                           0.53      5314\n",
      "   macro avg       0.49      0.49      0.47      5314\n",
      "weighted avg       0.50      0.53      0.49      5314\n",
      "\n",
      "\n",
      "Decision Tree Results:\n",
      "Accuracy: 0.5706\n",
      "AUC-ROC: 0.5006\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Rotten       0.51      0.02      0.04      2283\n",
      "       Fresh       0.57      0.99      0.72      3031\n",
      "\n",
      "    accuracy                           0.57      5314\n",
      "   macro avg       0.54      0.50      0.38      5314\n",
      "weighted avg       0.54      0.57      0.43      5314\n",
      "\n",
      "\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.5576\n",
      "AUC-ROC: 0.4882\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Rotten       0.45      0.13      0.20      2283\n",
      "       Fresh       0.57      0.88      0.69      3031\n",
      "\n",
      "    accuracy                           0.56      5314\n",
      "   macro avg       0.51      0.50      0.45      5314\n",
      "weighted avg       0.52      0.56      0.48      5314\n",
      "\n",
      "\n",
      "==================================================\n",
      "STEP 5: PERFORMANCE TUNING & OPTIMIZATION\n",
      "==================================================\n",
      "Performing hyperparameter tuning...\n",
      "\n",
      "Best Logistic Regression Params: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Logistic Regression CV Accuracy: 0.5704\n",
      "\n",
      "Best Decision Tree Params: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best Decision Tree CV Accuracy: 0.5705\n",
      "\n",
      "Best Naive Bayes Params: {'alpha': 2.0}\n",
      "Best Naive Bayes CV Accuracy: 0.5516\n",
      "\n",
      "Evaluating tuned models on test data...\n",
      "\n",
      "Tuned Logistic Regression Results:\n",
      "Accuracy: 0.5704\n",
      "AUC-ROC: 0.5013\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Rotten       0.00      0.00      0.00      2283\n",
      "       Fresh       0.57      1.00      0.73      3031\n",
      "\n",
      "    accuracy                           0.57      5314\n",
      "   macro avg       0.29      0.50      0.36      5314\n",
      "weighted avg       0.33      0.57      0.41      5314\n",
      "\n",
      "\n",
      "Tuned Decision Tree Results:\n",
      "Accuracy: 0.5706\n",
      "AUC-ROC: 0.5032\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Rotten       0.51      0.02      0.03      2283\n",
      "       Fresh       0.57      0.99      0.72      3031\n",
      "\n",
      "    accuracy                           0.57      5314\n",
      "   macro avg       0.54      0.50      0.38      5314\n",
      "weighted avg       0.54      0.57      0.43      5314\n",
      "\n",
      "\n",
      "Tuned Naive Bayes Results:\n",
      "Accuracy: 0.5572\n",
      "AUC-ROC: 0.4882\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Rotten       0.43      0.10      0.16      2283\n",
      "       Fresh       0.57      0.90      0.70      3031\n",
      "\n",
      "    accuracy                           0.56      5314\n",
      "   macro avg       0.50      0.50      0.43      5314\n",
      "weighted avg       0.51      0.56      0.47      5314\n",
      "\n",
      "\n",
      "Best Logistic Regression model saved as 'best_logistic_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Movie Review Sentiment Analysis - Rotten vs Fresh Prediction\n",
    "# Models: Logistic Regression + Decision Tree + Naive Bayes\n",
    "# Threshold: 60% (>=60 = Fresh, <60 = Rotten)\n",
    "\n",
    "# ==========================================\n",
    "# STEP (1) Problem Definition, Scoping & Framing\n",
    "# ==========================================\n",
    "\n",
    "# 1.1) Load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MOVIE REVIEW SENTIMENT ANALYSIS PROJECT\")\n",
    "print(\"Models: Logistic Regression + Decision Tree + Naive Bayes\")\n",
    "print(\"Threshold: >=60% = Fresh, <60% = Rotten\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df = pd.read_csv('rotten_tomatoes_movies.csv')\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# ==========================================\n",
    "# STEP (2) Data Exploration & Understanding\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 2: DATA EXPLORATION & UNDERSTANDING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nTomatometer Status Distribution:\")\n",
    "print(df['tomatometer_status'].value_counts())\n",
    "\n",
    "print(\"\\nTomatometer Rating Statistics:\")\n",
    "print(df['tomatometer_rating'].describe())\n",
    "\n",
    "# ==========================================\n",
    "# STEP (3) Data Preparation & Feature Engineering\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 3: DATA PREPARATION & FEATURE ENGINEERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "df['review_content_clean'] = df['review_content'].apply(clean_text)\n",
    "df['review_content_clean'] = df['review_content_clean'].fillna('')\n",
    "\n",
    "print(\"Text cleaning completed!\")\n",
    "print(f\"Sample cleaned text: {df['review_content_clean'].iloc[0][:100]}...\")\n",
    "\n",
    "def extract_text_features(df):\n",
    "    df['review_length'] = df['review_content_clean'].str.len()\n",
    "    df['word_count'] = df['review_content_clean'].str.split().str.len()\n",
    "    df['sentence_count'] = df['review_content_clean'].str.count('\\.') + 1\n",
    "    df['avg_word_length'] = df['review_content_clean'].apply(\n",
    "        lambda x: np.mean([len(word) for word in x.split()]) if x else 0\n",
    "    )\n",
    "    df['sentiment_polarity'] = df['review_content_clean'].apply(\n",
    "        lambda x: TextBlob(x).sentiment.polarity if x else 0\n",
    "    )\n",
    "    df['sentiment_subjectivity'] = df['review_content_clean'].apply(\n",
    "        lambda x: TextBlob(x).sentiment.subjectivity if x else 0\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df = extract_text_features(df)\n",
    "\n",
    "def create_target_variable(df, threshold=60):\n",
    "    df['target'] = (df['tomatometer_rating'] >= threshold).astype(int)\n",
    "    df['target_label'] = df['target'].map({1: 'Fresh', 0: 'Rotten'})\n",
    "    return df\n",
    "\n",
    "df = create_target_variable(df)\n",
    "\n",
    "print(f\"\\nTarget variable created with threshold: 60%\")\n",
    "print(\"Target distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "# ==========================================\n",
    "# STEP (4) ML Model Selection & Evaluation\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 4: ML MODEL SELECTION & EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=1,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "X_text = vectorizer.fit_transform(df['review_content_clean']).toarray()\n",
    "\n",
    "numerical_features = ['review_length', 'word_count', 'sentence_count', \n",
    "                     'avg_word_length', 'sentiment_polarity', 'sentiment_subjectivity']\n",
    "X_numerical = df[numerical_features].fillna(0).values\n",
    "\n",
    "# Combine features for LR and DT\n",
    "X_combined = np.hstack([X_text, X_numerical])\n",
    "y = df['target'].values\n",
    "\n",
    "# Split data for combined features (LR, DT)\n",
    "X_train_comb, X_test_comb, y_train_comb, y_test_comb = train_test_split(\n",
    "    X_combined, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split data for text features only (NB)\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n",
    "    X_text, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size (combined features): {X_train_comb.shape}\")\n",
    "print(f\"Test set size (combined features): {X_test_comb.shape}\")\n",
    "print(f\"Training set size (text features only): {X_train_text.shape}\")\n",
    "print(f\"Test set size (text features only): {X_test_text.shape}\")\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    if y_pred_proba is not None:\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(f\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Rotten', 'Fresh']))\n",
    "    return model, accuracy\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "trained_models = {}\n",
    "\n",
    "# Logistic Regression and Decision Tree use combined features\n",
    "for name in ['Logistic Regression', 'Decision Tree']:\n",
    "    trained_model, accuracy = evaluate_model(models[name], X_train_comb, X_test_comb, y_train_comb, y_test_comb, name)\n",
    "    model_results[name] = accuracy\n",
    "    trained_models[name] = trained_model\n",
    "\n",
    "# Naive Bayes uses text features only\n",
    "trained_model_nb, accuracy_nb = evaluate_model(models['Naive Bayes'], X_train_text, X_test_text, y_train_text, y_test_text, 'Naive Bayes')\n",
    "model_results['Naive Bayes'] = accuracy_nb\n",
    "trained_models['Naive Bayes'] = trained_model_nb\n",
    "\n",
    "# ==========================================\n",
    "# STEP (5) Performance Tuning & Optimization\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 5: PERFORMANCE TUNING & OPTIMIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"Performing hyperparameter tuning...\")\n",
    "\n",
    "# Logistic Regression tuning\n",
    "lr_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "lr_grid = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), lr_params, cv=3, scoring='accuracy')\n",
    "lr_grid.fit(X_train_comb, y_train_comb)\n",
    "\n",
    "# Decision Tree tuning\n",
    "dt_params = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=3, scoring='accuracy')\n",
    "dt_grid.fit(X_train_comb, y_train_comb)\n",
    "\n",
    "# Naive Bayes tuning\n",
    "nb_params = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "nb_grid = GridSearchCV(MultinomialNB(), nb_params, cv=3, scoring='accuracy')\n",
    "nb_grid.fit(X_train_text, y_train_text)\n",
    "\n",
    "print(f\"\\nBest Logistic Regression Params: {lr_grid.best_params_}\")\n",
    "print(f\"Best Logistic Regression CV Accuracy: {lr_grid.best_score_:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Decision Tree Params: {dt_grid.best_params_}\")\n",
    "print(f\"Best Decision Tree CV Accuracy: {dt_grid.best_score_:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Naive Bayes Params: {nb_grid.best_params_}\")\n",
    "print(f\"Best Naive Bayes CV Accuracy: {nb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate tuned models on test set\n",
    "best_lr = lr_grid.best_estimator_\n",
    "best_dt = dt_grid.best_estimator_\n",
    "best_nb = nb_grid.best_estimator_\n",
    "\n",
    "print(\"\\nEvaluating tuned models on test data...\")\n",
    "\n",
    "evaluate_model(best_lr, X_train_comb, X_test_comb, y_train_comb, y_test_comb, \"Tuned Logistic Regression\")\n",
    "evaluate_model(best_dt, X_train_comb, X_test_comb, y_train_comb, y_test_comb, \"Tuned Decision Tree\")\n",
    "evaluate_model(best_nb, X_train_text, X_test_text, y_train_text, y_test_text, \"Tuned Naive Bayes\")\n",
    "\n",
    "# ==========================================\n",
    "# Optional: Save the best Logistic Regression model\n",
    "import pickle\n",
    "\n",
    "with open('best_logistic_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_lr, f)\n",
    "\n",
    "print(\"\\nBest Logistic Regression model saved as 'best_logistic_model.pkl'\")\n",
    "\n",
    "# ==========================================\n",
    "# End of Script\n",
    "# ==========================================\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(00) Python 3.9 - ML",
   "language": "python",
   "name": "py39_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
